了解です。**案1「24時間AIラジオ局 – Radio‑24」**を、**デモ映え＋最新トレンド実装**に最適化した設計でまとめます。
（前提：**Next.js 15 + React 19 / Go(Cloud Run) / PostgreSQL(+pgvector)**、音声は**OpenAI Realtime API**の**WebRTC**接続を中核にします）

---

## 1. コンセプト（審査員に刺さる一言）

**「24時間、AIパーソナリティが“生声”で喋り続ける対話型ラジオ」**

* 時報（毎正時）で**時間帯テーマ**が切り替え。
* リスナーは\*\*押して話す（PTT）\*\*で“その場”で会話参加。
* **電話（SIP）での入電デモ**も可能（時間があれば）。
  → **Realtime API GA**の“**本番運用向け音声エージェント**”機能を前面に出します（**gpt‑realtime**、SIP、MCP、画像入力対応など）。([OpenAI][1])

---

## 2. 45秒デモ台本（そのまま使える）

1. 画面に**波形＋「ON AIR」**。
2. 「**今は“深夜のひらめき”の時間。30秒だけ投稿どうぞ**」とAIが案内。
3. 参加者がPTTで質問 → **AIが即レス**、キーワードを**字幕**に反映。
4. **毎正時**のジングルでテーマが**自動切替**（UIのテーマ色が変わる）。
5. **（伸び代）電話入電**：「ラジオに電話が来ました」→SIPで双方向通話。
6. 最後に\*\*“24時間の名場面”\*\*クリップ（1分）を自動生成して終了。

※ Realtime APIの**GA版は音声→音声の低遅延対話**に最適化、**SIP通話も公式対応**。声質強化の**Marin/Cedar**などの新ボイスが使えます。([OpenAI][1])

---

## 3. 全体アーキテクチャ

```mermaid
flowchart LR
  subgraph Client
    UI[Next.js 15 + React 19 (PWA)] --> Mic[PTT/音声入力]
    Mic --> WebRTC[WebRTC to OpenAI Realtime]
    UI --> WS1[WS: 視聴者数/字幕/NowPlaying]
  end

  subgraph OpenAI
    WebRTC -- Bi-directional Audio/Text --> RT[Realtime API (gpt-realtime)]
    RT -. Function Calling .-> Tools[MCP/外部ツール(天気/カレンダー等)]
  end

  subgraph Backend (Cloud Run / Go)
    API[(REST)] -- "ephemeral client secret\n(ブラウザ用・短命)" --> UI
    API --> DB[(PostgreSQL + pgvector)]
    API --> WS2[WS: ランキング/テーマ配信]
    Sched[Cloud Scheduler] --> API
  end

  UI <-- WS2 --> API
  RT <-- SIP --> Tel[電話ゲートウェイ(任意: Twilio等)]
```

* **WebRTC直結**で**超低遅延の音声対話**（GA）。**SIP**は拡張（時間があれば）。([OpenAI][1])
* **サーバ（Go）**は**ephemeralなクライアント秘密情報の発行**、番組編成、投稿メタデータ管理。
* **字幕・ハイライト**や**おすすめ投稿**は**pgvector**でセマンティック検索。([GitHub][2])
* **UI/配信**は**Next.js 15.5**（React 19対応）で最新。([Next.js][3])

---

## 4. 主要機能（MVP → 受賞レベル）

### MVP（8〜12時間実装想定）

* **A. 音声対話の芯**：PTT→WebRTC接続→AIの**即時応答**（音声/字幕）。

  * GA版Realtimeは**長時間セッション**/**サーバVAD**/**非同期ファンクションコール**など改善点が明確。**idle timeout**等の設定も可能。([OpenAI Developers][4])
* **B. 毎正時テーマ**：Schedulerでテーマを切替→WSでUI配信。
* **C. 投稿キュー**：短音声・短文投稿を**pgvector**でクラスタ化→「今夜の話題」表示。([GitHub][2])
* **D. デモ録音**：最後に**名場面1分**を自動合成（BGMは自作or無償素材のみ）。

### 受賞レベルの伸ばし（＋4〜8時間）

* **E. 電話入電（SIP）**：1本だけでも\*\*“電話が鳴るラジオ”\*\*のインパクト大。([OpenAI][1])
* **F. MCP連携**：天気/ニュース/社内FAQなど**外部ツール**を安全に呼ぶ。([OpenAI][1])
* **G. LiveKitブリッジ（選択）**：多数同時接続や録音・ミキシングを**楽に**。([LiveKit Docs][5])

---

## 5. 画面構成（Next.js 15 + React 19）

* **/ (ON AIR)**：波形・字幕・PTTボタン・今のテーマ・視聴者数
* **/clips**：24時間の時報ごとに自動生成された**24連ショート**
* **/submit**：投稿フォーム（PTT or 文字）
* **/admin**：番組表（テーマ編集, BGM/ジングル切替, NGワード）

> Next.js 15は**安定版**、**15.5**で改善が入り、React 19は**正式対応**。**RSC/Actions**を使って軽量に実装可能。([Next.js][6])

---

## 6. データ設計（要点のみ）

```mermaid
erDiagram
  USER ||--o{ SUBMISSION : makes
  SHOW ||--o{ THEME : has
  SHOW ||--o{ CLIP : aggregates
  SUBMISSION {
    uuid id PK
    uuid user_id
    text type   // audio|text
    text text   // transcript
    vector(1536) embed    // pgvector
    timestamptz at
  }
  THEME {
    uuid id PK
    uuid show_id
    int hour // 0..23
    text title
    text prompt_guidance // Realtimeへの指示
  }
  CLIP {
    uuid id PK
    uuid show_id
    int hour
    text url
  }
```

* **pgvector**に`embed`を格納し、類似投稿・話題抽出・ハイライト選定に活用。([GitHub][2])

---

## 7. Realtimeセッション設計（GA準拠）

* **接続**：

  1. ブラウザ → **Go API**へアクセス、\*\*短命のクライアント秘密情報（ephemeral）\*\*を受け取る
  2. ブラウザ → **WebRTC**でRealtimeへ接続、**音声in/out & テキスト**を双方向ストリーム
* **会話管理**：

  * **server VAD**/ **idle timeout**で聞き取り待機を自動ハンドリング
  * **非同期ファンクションコール**でツール実行中も会話継続（待ちメッセージは自動で適切化）
* **セッション長/コンテキスト**：長時間セッション対応・トークン上限/トランケーションの注意点あり（GAで仕様更新）。([OpenAI Developers][4])

> **補足**：Realtimeの**GA発表（2025/08/28）**で**SIP**や**MCP**などが強化。**音声品質/指示追従/関数呼び出し**も改善。([OpenAI][1])

---

## 8. 推し実装テク（“今っぽさ”の訴求点）

* **OpenAI Realtime（WebRTC直）**：**音声↔音声**の低遅延を“体験”で示す（GA）。([OpenAI][1])
* **React 19 / Next.js 15.5**：RSC/Actionsで**サーバ連携最小のUI**を高速に。([Next.js][3])
* **pgvector**：**セマンティック話題集約/おすすめ**に使う（純Postgresで完結）。([GitHub][2])
* **（選択）LiveKitブリッジ**：**大量視聴・録音・ミキシング**を安定運用へ。([LiveKit Docs][5])

---

## 9. API（自作バックエンド：抜粋）

```http
POST /api/realtime/ephemeral
- auth済みユーザに短命クライアント秘密情報を発行（数十秒〜数分）

POST /api/theme/rotate
- {hour}指定で現在テーマ更新（Cloud Schedulerから叩く）

GET  /api/clip/latest?limit=24
- 生成済みショートの一覧を返す
```

> RealtimeへのWebRTC接続・イベント形状は**GAで形が更新**されているため、**公式ドキュメント/開発者ノート**に沿って実装します（β→GAの差分に注意）。([OpenAI Developers][4])

---

## 10. 具体的なフロー（MVP時の“芯”）

1. **/api/realtime/ephemeral**で**短命クライアント秘密**を取得
2. フロントが**WebRTC**でRealtimeへ接続（音声送受・字幕受信）
3. **毎正時**：Scheduler→Go API→**WS配信**でテーマ/ジングル切替
4. 投稿は`/submit`で受け→**埋め込み生成→pgvector**に格納→**類似投稿**をON AIRへレコメンド
5. 終了時に**24連ショート**（24本×5秒など）を自動連結

---

## 11. 体験のチューニング（Realtime特有のコツ）

* **“話速を上げる”**：`speed`は**再生速度**で、**喋り方自体**は**プロンプト**で指定するのがコツ（Realtimeのプロンプト・ガイドが参考）。([OpenAI Cookbook][7])
* **割り込み**：LiveKit経由の場合、**発話割り込み/ダッキング**がSDK側で扱いやすい。([LiveKit Docs][8])
* **長時間運用**：**idle timeout**や**トランケーション**の設定で**会話途切れ/コスト**を制御。([OpenAI Developers][4])

---

## 12. セキュリティ/著作権・モデレーション

* **鍵の取り扱い**：**ブラウザ直渡し禁止**。必ず**短命のクライアント秘密**をサーバから交付。([OpenAI Developers][4])
* **投稿の扱い**：**公序良俗/個人情報**の読み上げ防止。簡易NGワード＋再読上限。
* **音源**：BGM/ジングルは**自作/フリー素材限定**（楽曲ストリーミング等の著作権侵害は不可）。

---

## 13. デプロイ/運用

* **Cloud Run**（Go API/WS）＋**Cloud SQL(Postgres)**＋**Scheduler**。
* **Observability**：Cloud Logging + メトリクス、**エージェント側はトレースID**を埋め込み。
* **CI**：GitHub Actions → Cloud Run Deploy。
* **負荷対策**：

  * WebRTCは**OpenAI側に直接**接続（媒体はOpenAIの**Realtime**）。
  * ハイライト生成/埋め込みは**非同期ジョブ**化。

---

## 14. 初期実装プラン（6ブロックで最短着地）

1. **PTT→Realtime音声応答**（字幕表示まで）
2. **テーマ切替**（毎正時、色とジングル変化）
3. **投稿→pgvector格納→似てる投稿を3件**
4. **24連ショート生成**（単純連結）
5. **視聴者数/NowPlaying**（WSで配信）
6. （**伸び代**）**SIP入電** or **LiveKitブリッジ**

---

## 15. “勝ちポイント”の見せ方（ピッチ資料）

* **1枚目**：\*\*「24時間喋り続けるAI」\*\*の波形スクショ
* **2枚目**：**アーキ図**（WebRTC↔Realtime、Tools、pgvector）
* **3枚目**：**テーマ時報**と**名場面の24連ショート**
* **4枚目**：**技術の新しさ**（Realtime GA / SIP / MCP / Next 15.5 / React 19 / pgvector）

  * Realtime **GA & gpt‑realtime / SIP / MCP**。([OpenAI][1])
  * Realtime **GA変更点/idle timeout/非同期FC**。([OpenAI Developers][4])
  * **Next.js 15.5/React 19**安定対応。([Next.js][3])
  * **pgvector**で話題集約。([GitHub][2])
  * **LiveKitブリッジ**（大規模/録音向け）。([LiveKit Docs][5])

---。

[1]: https://openai.com/index/introducing-gpt-realtime/?utm_source=chatgpt.com "Introducing gpt-realtime and Realtime API updates for ..."
[2]: https://github.com/pgvector/pgvector?utm_source=chatgpt.com "pgvector/pgvector: Open-source vector similarity search for ..."
[3]: https://nextjs.org/blog/next-15-5?utm_source=chatgpt.com "Next.js 15.5"
[4]: https://developers.openai.com/blog/realtime-api/?utm_source=chatgpt.com "Developer notes on the Realtime API"
[5]: https://docs.livekit.io/agents/integrations/realtime/openai/?utm_source=chatgpt.com "OpenAI Realtime API integration guide"
[6]: https://nextjs.org/blog/next-15?utm_source=chatgpt.com "Next.js 15"
[7]: https://cookbook.openai.com/examples/realtime_prompting_guide?utm_source=chatgpt.com "Realtime Prompting Guide"
[8]: https://docs.livekit.io/agents/openai/overview/?utm_source=chatgpt.com "OpenAI and LiveKit"
