'use client';

import { useRef, useState, useEffect } from 'react';
import { Box, Button, VStack, Text, HStack } from '@chakra-ui/react';
import { Room, RoomEvent, RemoteTrackPublication, RemoteAudioTrack } from 'livekit-client';

export default function OnAir() {
  const [connected, setConnected] = useState(false);
  const [subtitles, setSubtitles] = useState('');
  const [displayedSubtitles, setDisplayedSubtitles] = useState('');
  const [subtitleStack, setSubtitleStack] = useState<Array<{text: string, id: string, timestamp: Date}>>([]);
  const [theme, setTheme] = useState({ title: 'Radio-24', color: '#1a1a2e' });
  const [ws, setWs] = useState<WebSocket | null>(null);
  const [broadcastWs, setBroadcastWs] = useState<WebSocket | null>(null);
  const [dialogueRequested, setDialogueRequested] = useState(false);
  const [dialogueActive, setDialogueActive] = useState(false);
  const [isRecording, setIsRecording] = useState(false);
  const [myClientId, setMyClientId] = useState<string>('');
  const [dialogueRequester, setDialogueRequester] = useState<string>('');
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const audioChunksRef = useRef<Blob[]>([]);
  const roomRef = useRef<Room | null>(null);
  const remoteAudioRef = useRef<HTMLAudioElement>(null);
  const subtitleTimeoutRef = useRef<NodeJS.Timeout | null>(null);
  const typewriterTimeoutRef = useRef<NodeJS.Timeout | null>(null);
  const currentSubtitleIdRef = useRef<string>('');

  const API_BASE = process.env.NEXT_PUBLIC_API_BASE || 'http://localhost:8080';

  useEffect(() => {
    // PTT WebSocketæ¥ç¶š
    const wsUrl = API_BASE.replace('http', 'ws') + '/ws/ptt';
    const websocket = new WebSocket(wsUrl);
    
    websocket.onopen = () => {
      console.log('PTT WebSocket connected');
      // æ¥ç¶šæ™‚ã«ç¾åœ¨ã®å¯¾è©±çŠ¶æ…‹ã‚’ç¢ºèª
      checkDialogueStatus();
    };
    
    websocket.onmessage = (event) => {
      const data = JSON.parse(event.data);
      if (data.type === 'ptt_queued') {
        console.log('PTT queued:', data.id);
      } else if (data.type === 'dialogue_queued') {
        console.log('Dialogue queued:', data.id);
        setDialogueRequested(true);
        // ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆIDã‚’ä¿å­˜
        if (data.client_id) {
          setMyClientId(data.client_id);
        }
      } else if (data.type === 'dialogue_end_ack') {
        console.log('Dialogue end acknowledged');
        setDialogueActive(false);
        setDialogueRequested(false);
      } else if (data.type === 'dialogue_ended') {
        console.log('Dialogue ended by server');
        setDialogueActive(false);
        setDialogueRequested(false);
        setDialogueRequester('');
      }
    };
    
    websocket.onclose = (event) => {
      console.log('PTT WebSocket closed:', event.code, event.reason);
      // WebSocketåˆ‡æ–­æ™‚ã«çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
      setDialogueActive(false);
      setDialogueRequested(false);
    };
    
    websocket.onerror = (error) => {
      console.error('PTT WebSocket error:', error);
      // ã‚¨ãƒ©ãƒ¼æ™‚ã‚‚çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
      setDialogueActive(false);
      setDialogueRequested(false);
      setDialogueRequester('');
    };
    
    setWs(websocket);
    
    // ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒˆWebSocketæ¥ç¶š
    const broadcastWsUrl = API_BASE.replace('http', 'ws') + '/ws/broadcast';
    const broadcastWebsocket = new WebSocket(broadcastWsUrl);
    
    broadcastWebsocket.onopen = () => {
      console.log('Broadcast WebSocket connected');
    };
    
    broadcastWebsocket.onmessage = (event) => {
      const data = JSON.parse(event.data);
      console.log('Broadcast message received:', data);
      
      if (data.type === 'dialogue_ready') {
        console.log('Dialogue ready:', data);
        // ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æ§‹é€ ã«åˆã‚ã›ã¦ä¿®æ­£
        const messageData = data.data || data;
        console.log('Request ID:', messageData.id);
        console.log('Client ID:', messageData.client_id);
        setDialogueActive(true);
        setDialogueRequested(false);
        // å¯¾è©±ã‚’ãƒªã‚¯ã‚¨ã‚¹ãƒˆã—ãŸã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’è¨˜éŒ²
        if (messageData.client_id) {
          setDialogueRequester(messageData.client_id);
          console.log('Set dialogue requester to:', messageData.client_id);
        } else {
          console.log('No client_id in dialogue_ready message');
        }
      } else if (data.type === 'dialogue_ended') {
        console.log('Dialogue ended via broadcast');
        setDialogueActive(false);
        setDialogueRequested(false);
        setDialogueRequester('');
      } else if (data.type === 'subtitle') {
        console.log('Subtitle received:', data.data.text);
        
        // æ—¢å­˜ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’ã‚¯ãƒªã‚¢
        if (subtitleTimeoutRef.current) {
          clearTimeout(subtitleTimeoutRef.current);
        }
        if (typewriterTimeoutRef.current) {
          clearTimeout(typewriterTimeoutRef.current);
        }
        
        // ç¾åœ¨è¡¨ç¤ºä¸­ã®å­—å¹•ãŒã‚ã‚‹å ´åˆã¯ã€ãã‚Œã‚’ã‚¹ã‚¿ãƒƒã‚¯ã«è¿½åŠ 
        if (currentSubtitleIdRef.current && subtitles) {
          setSubtitleStack(prev => {
            const newStack = [...prev, {
              text: subtitles,
              id: currentSubtitleIdRef.current,
              timestamp: new Date()
            }];
            // æœ€å¤§3ã¤ã«åˆ¶é™ï¼ˆå¤ã„ã‚‚ã®ã‹ã‚‰å‰Šé™¤ï¼‰
            return newStack.slice(-3);
          });
        }
        
        // æ–°ã—ã„å­—å¹•ã‚’è¨­å®š
        setSubtitles(data.data.text);
        
        // æ–°ã—ã„å­—å¹•IDã‚’ç”Ÿæˆ
        const subtitleId = `subtitle-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`;
        currentSubtitleIdRef.current = subtitleId;
        
        // ã‚¿ã‚¤ãƒ—ãƒ©ã‚¤ã‚¿ãƒ¼åŠ¹æœã§å­—å¹•ã‚’è¡¨ç¤º
        startTypewriterEffect(data.data.text, subtitleId);
        
        // 50ç§’å¾Œã«ç¾åœ¨ã®å­—å¹•ã‚’ã‚¯ãƒªã‚¢ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ï¼‰
        subtitleTimeoutRef.current = setTimeout(() => {
          setSubtitles('');
          setDisplayedSubtitles('');
          currentSubtitleIdRef.current = '';
        }, 50000);
      }
    };
    
    broadcastWebsocket.onerror = (error) => {
      console.error('Broadcast WebSocket error:', error);
    };
    
    broadcastWebsocket.onclose = (event) => {
      console.log('Broadcast WebSocket closed:', event.code, event.reason);
      // ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒˆWebSocketåˆ‡æ–­æ™‚ã‚‚çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
      setDialogueActive(false);
      setDialogueRequested(false);
      setDialogueRequester('');
    };
    
    setBroadcastWs(broadcastWebsocket);
    
    return () => {
      websocket.close();
      broadcastWebsocket.close();
      // ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’ã‚¯ãƒªã‚¢
      if (subtitleTimeoutRef.current) {
        clearTimeout(subtitleTimeoutRef.current);
      }
      if (typewriterTimeoutRef.current) {
        clearTimeout(typewriterTimeoutRef.current);
      }
    };
  }, [API_BASE]);

  // ãƒšãƒ¼ã‚¸é›¢è„±æ™‚ã®ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—å‡¦ç†
  useEffect(() => {
    const handleBeforeUnload = () => {
      if (dialogueActive && ws && ws.readyState === WebSocket.OPEN) {
        // å¯¾è©±ãƒ¢ãƒ¼ãƒ‰ä¸­ãªã‚‰çµ‚äº†ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡
        const message = {
          type: 'dialogue_end',
          kind: 'dialogue'
        };
        ws.send(JSON.stringify(message));
        console.log('Dialogue end request sent on page unload');
        
        // å¯¾è©±çŠ¶æ…‹ã‚’å³åº§ã«ç„¡åŠ¹åŒ–
        setDialogueActive(false);
      }
    };

    const handleVisibilityChange = () => {
      // visibilitychangeã§ã¯å¯¾è©±ã‚’çµ‚äº†ã—ãªã„
      // ã‚¿ãƒ–åˆ‡ã‚Šæ›¿ãˆã‚„ä»–ã®ã‚¢ãƒ—ãƒªã¸ã®ãƒ•ã‚©ãƒ¼ã‚«ã‚¹ç§»å‹•ã§å¯¾è©±ãŒçµ‚äº†ã™ã‚‹ã®ã‚’é˜²ã
      if (document.visibilityState === 'hidden' && dialogueActive) {
        console.log('Page became hidden during dialogue - keeping dialogue active');
      }
    };

    window.addEventListener('beforeunload', handleBeforeUnload);
    document.addEventListener('visibilitychange', handleVisibilityChange);
    
    return () => {
      window.removeEventListener('beforeunload', handleBeforeUnload);
      document.removeEventListener('visibilitychange', handleVisibilityChange);
    };
  }, [dialogueActive, ws]);

  // ã‚¿ã‚¤ãƒ—ãƒ©ã‚¤ã‚¿ãƒ¼åŠ¹æœã®å®Ÿè£…
  const startTypewriterEffect = (text: string, subtitleId: string) => {
    setDisplayedSubtitles('');
    let index = 0;
    
    const typeNextChar = () => {
      // å­—å¹•IDãŒå¤‰ã‚ã£ãŸå ´åˆã¯åœæ­¢
      if (currentSubtitleIdRef.current !== subtitleId) {
        return;
      }
      
      if (index < text.length) {
        setDisplayedSubtitles(text.slice(0, index + 1));
        index++;
        // æ—¥æœ¬èªã®å ´åˆã¯å°‘ã—é…ã‚ã€è‹±æ•°å­—ãƒ»è¨˜å·ã¯é€Ÿã‚ã«è¨­å®š
        const char = text[index - 1];
        const delay = /[ã²ã‚‰ãŒãªã‚«ã‚¿ã‚«ãƒŠæ¼¢å­—]/.test(char) ? 80 : 40;
        typewriterTimeoutRef.current = setTimeout(typeNextChar, delay);
      }
    };
    
    typeNextChar();
  };

  // å¯¾è©±çŠ¶æ…‹ç¢ºèªé–¢æ•°
  const checkDialogueStatus = async () => {
    try {
      const response = await fetch(`${API_BASE}/v1/dialogue/status`);
      const data = await response.json();
      setDialogueActive(data.active || false);
      setDialogueRequested(data.requested || false);
      setDialogueRequester(data.requested_by || '');
      console.log('Dialogue status checked:', data);
    } catch (error) {
      console.error('Failed to check dialogue status:', error);
      // ã‚¨ãƒ©ãƒ¼æ™‚ã¯çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
      setDialogueActive(false);
      setDialogueRequested(false);
      setDialogueRequester('');
    }
  };

  async function connect() {
    try {
      const res = await fetch(`${API_BASE}/v1/room/join`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ identity: crypto.randomUUID() })
      });
      
      const { url, token } = await res.json();
      
      const room = new Room();
      await room.connect(url, token);
      
      roomRef.current = room;
      
      // å‚åŠ è€…æƒ…å ±ã‚’ãƒ­ã‚°ã«å‡ºåŠ›
      console.log('Connected to room:', room.name);
      console.log('Participants:', room.numParticipants);
      room.remoteParticipants.forEach((participant) => {
        console.log('Participant:', participant.identity, 'tracks:', participant.audioTrackPublications.size);
      });
      
      room.on(RoomEvent.TrackSubscribed, (_track, publication, _participant) => {
        const track = (publication as RemoteTrackPublication).track as RemoteAudioTrack;
        console.log('Track subscribed:', track?.kind, publication.source);
        if (track) {
          track.attach(); // è‡ªå‹•å†ç”Ÿ
          console.log('Audio track attached');
        }
      });
      
      room.on(RoomEvent.TrackUnsubscribed, (track, publication, _participant) => {
        const audioTrack = (publication as RemoteTrackPublication).track as RemoteAudioTrack;
        if (audioTrack) {
          audioTrack.detach();
        }
      });
      
      setConnected(true);
    } catch (error) {
      console.error('Failed to join room:', error);
    }
  }

  function disconnect() {
    if (roomRef.current) {
      roomRef.current.disconnect();
      roomRef.current = null;
    }
    setConnected(false);
    setSubtitles('');
    setDisplayedSubtitles('');
    setSubtitleStack([]);
    setDialogueRequested(false);
    setDialogueActive(false);
    setDialogueRequester('');
  }

  async function requestDialogue() {
    if (!ws) return;
    
    try {
      const message = {
        type: 'dialogue_request',
        kind: 'dialogue'
      };
      ws.send(JSON.stringify(message));
      setDialogueRequested(true);
      console.log('Dialogue request sent');
    } catch (error) {
      console.error('Failed to send dialogue request:', error);
    }
  }

  async function endDialogue() {
    if (!ws || !dialogueActive) return;
    
    try {
      const message = {
        type: 'dialogue_end',
        kind: 'dialogue'
      };
      ws.send(JSON.stringify(message));
      // çŠ¶æ…‹ã¯ã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰ã®å¿œç­”ã§æ›´æ–°ã•ã‚Œã‚‹
      console.log('Dialogue end request sent');
    } catch (error) {
      console.error('Failed to send dialogue end request:', error);
      // ã‚¨ãƒ©ãƒ¼æ™‚ã¯æ‰‹å‹•ã§çŠ¶æ…‹ã‚’ãƒªã‚»ãƒƒãƒˆ
      setDialogueActive(false);
      setDialogueRequested(false);
    }
  }


  return (
    <Box 
      minH="100vh" 
      bg={theme.color} 
      color="white" 
      p={6}
      transition="background-color 0.3s ease"
    >
      <VStack gap={6} align="stretch">
        <Box textAlign="center">
          <Text fontSize="4xl" fontWeight="bold" mb={2}>
            Radioâ€‘24 â€” ON AIR
          </Text>
          <Text fontSize="xl" color="gray.300">
            {theme.title}
          </Text>
        </Box>

        <HStack gap={4} justify="center">
          {!connected ? (
            <Button 
              onClick={connect} 
              colorScheme="blue" 
              size="lg"
              bg="blue.500"
              _hover={{ bg: "blue.600" }}
            >
              æ¥ç¶š
            </Button>
          ) : (
            <Button 
              onClick={disconnect} 
              colorScheme="red" 
              size="lg"
              bg="red.500"
              _hover={{ bg: "red.600" }}
            >
              åˆ‡æ–­
            </Button>
          )}

          {!dialogueRequested && !dialogueActive ? (
            <Button 
              onClick={requestDialogue}
              disabled={!connected}
              colorScheme="yellow"
              size="lg"
              bg="yellow.500"
              _hover={{ bg: "yellow.600" }}
              _disabled={{ bg: "gray.500" }}
            >
              ğŸ’¬ å¯¾è©±ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
            </Button>
          ) : dialogueRequested ? (
            <Button 
              disabled
              colorScheme="orange"
              size="lg"
              bg="orange.500"
            >
              â³ å¯¾è©±å¾…æ©Ÿä¸­...
            </Button>
          ) : (
            <Button 
              onClick={endDialogue}
              colorScheme="red"
              size="lg"
              bg="red.500"
              _hover={{ bg: "red.600" }}
            >
              ğŸ”š å¯¾è©±çµ‚äº†
            </Button>
          )}

        </HStack>

        <Box 
          bg="blackAlpha.600" 
          p={6} 
          borderRadius="md"
          minH="400px"
          maxH="600px"
          border="1px solid"
          borderColor="whiteAlpha.200"
          overflowY="auto"
        >
          <Text fontSize="lg" fontWeight="bold" mb={4} color="blue.200">
            ğŸ“º å­—å¹•å±¥æ­´:
          </Text>
          
          {/* ã‚¹ã‚¿ãƒƒã‚¯ã•ã‚ŒãŸå­—å¹• */}
          <VStack gap={3} align="stretch" mb={4}>
            {subtitleStack.map((subtitle) => (
              <Box
                key={subtitle.id}
                bg="whiteAlpha.100"
                p={3}
                borderRadius="md"
                border="1px solid"
                borderColor="whiteAlpha.200"
                opacity={0.8}
              >
                <Text 
                  fontSize="sm" 
                  color="gray.400" 
                  mb={1}
                >
                  {subtitle.timestamp.toLocaleTimeString()}
                </Text>
                <Text 
                  whiteSpace="pre-wrap"
                  fontSize="md"
                  lineHeight="1.6"
                  color="gray.200"
                  fontFamily="mono"
                >
                  {subtitle.text}
                </Text>
              </Box>
            ))}
          </VStack>
          
          {/* ç¾åœ¨ã®å­—å¹• */}
          {displayedSubtitles && (
            <Box
              bg="yellow.900"
              p={4}
              borderRadius="md"
              border="2px solid"
              borderColor="yellow.500"
              position="relative"
            >
              <Text 
                whiteSpace="pre-wrap" 
                fontSize="lg"
                lineHeight="1.8"
                color="yellow.100"
                fontFamily="mono"
              >
                {displayedSubtitles}
                {displayedSubtitles.length < subtitles.length && (
                  <Text as="span" color="yellow.300" animation="blink 1s infinite">
                    |
                  </Text>
                )}
              </Text>
            </Box>
          )}
          
          {/* å­—å¹•ãŒãªã„å ´åˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ */}
          {!displayedSubtitles && subtitleStack.length === 0 && (
            <Text 
              color="gray.400"
              fontStyle="italic"
              textAlign="center"
              py={8}
            >
              å­—å¹•ãŒã“ã“ã«è¡¨ç¤ºã•ã‚Œã¾ã™...
            </Text>
          )}
        </Box>

        {dialogueActive && (
          <VStack gap={6} align="stretch">
            {/* å¯¾è©±çŠ¶æ…‹ã®é€šçŸ¥ */}
            <Box 
              bg="yellow.900" 
              p={4} 
              borderRadius="md"
              border="2px solid"
              borderColor="yellow.500"
              animation="pulse 2s infinite"
            >
              <Text fontSize="lg" fontWeight="bold" color="yellow.200" mb={2}>
                ğŸ™ï¸ å¯¾è©±ãƒ¢ãƒ¼ãƒ‰ä¸­
              </Text>
              <Text fontSize="md" color="yellow.100" mb={2}>
                {dialogueRequester === myClientId 
                  ? "AI DJã¨å¯¾è©±ã§ãã¾ã™ã€‚ä¸‹ã®ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦è©±ã—ã¦ãã ã•ã„ã€‚"
                  : "ä»–ã®ãƒªã‚¹ãƒŠãƒ¼ãŒå¯¾è©±ä¸­ã§ã™ã€‚ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„ã€‚"
                }
              </Text>
              <Text fontSize="xs" color="gray.400" mb={2}>
                Debug: dialogueRequester={dialogueRequester}, myClientId={myClientId}
              </Text>
              <Text fontSize="sm" color="yellow.300">
                {dialogueRequester === myClientId ? (
                  <>
                    ğŸ’¡ ãƒœã‚¿ãƒ³ãŒ{isRecording ? "èµ¤è‰²ï¼ˆéŒ²éŸ³ä¸­ï¼‰" : "é»„è‰²ï¼ˆå¯¾è©±ä¸­ï¼‰"}ã«ãªã£ã¦ã„ã¾ã™ã€‚
                    {isRecording ? "è©±ã—çµ‚ã‚ã£ãŸã‚‰ãƒœã‚¿ãƒ³ã‚’é›¢ã—ã¦ãã ã•ã„ã€‚" : "æŠ¼ã—ç¶šã‘ã¦è©±ã—ã‹ã‘ã¦ãã ã•ã„ã€‚"}
                  </>
                ) : (
                  "ğŸ’¡ å¯¾è©±ã‚’ãƒªã‚¯ã‚¨ã‚¹ãƒˆã—ãŸãƒªã‚¹ãƒŠãƒ¼ã«ã®ã¿è©±ã™æ¨©é™ãŒã‚ã‚Šã¾ã™ã€‚"
                )}
              </Text>
            </Box>

            {/* PTTãƒœã‚¿ãƒ³ - å¯¾è©±çŠ¶æ…‹ã§ã‹ã¤è‡ªåˆ†ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å ´åˆã®ã¿è¡¨ç¤º */}
            {dialogueRequester === myClientId && (
              <Box textAlign="center">
                <Button
                  onMouseDown={startPTT}
                  onMouseUp={stopPTT}
                  onTouchStart={startPTT}
                  onTouchEnd={stopPTT}
                  disabled={!connected}
                  size="xl"
                  height="120px"
                  width="120px"
                  borderRadius="full"
                  fontSize="4xl"
                  fontWeight="bold"
                  colorScheme={isRecording ? "red" : "yellow"}
                  bg={isRecording ? "red.500" : "yellow.500"}
                  _hover={{ 
                    bg: isRecording ? "red.600" : "yellow.600",
                    transform: "scale(1.05)"
                  }}
                  _active={{ 
                    bg: isRecording ? "red.700" : "yellow.700",
                    transform: "scale(0.95)"
                  }}
                  _disabled={{ bg: "gray.500" }}
                  boxShadow="0 8px 32px rgba(0,0,0,0.3)"
                  transition="all 0.2s ease"
                >
                  ğŸ™ï¸
                </Button>
                <Text fontSize="lg" fontWeight="bold" mt={4} color="yellow.200">
                  {isRecording ? "ğŸ¤ éŒ²éŸ³ä¸­ - è©±ã—ã¦ãã ã•ã„" : "ğŸ¤ è©±ã™ãƒœã‚¿ãƒ³"}
                </Text>
                <Text fontSize="sm" color="yellow.300" mt={2}>
                  {isRecording 
                    ? "è©±ã—çµ‚ã‚ã£ãŸã‚‰ãƒœã‚¿ãƒ³ã‚’é›¢ã—ã¦ãã ã•ã„" 
                    : "ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ç¶šã‘ã¦è©±ã—ã‹ã‘ã¦ãã ã•ã„"
                  }
                </Text>
              </Box>
            )}
          </VStack>
        )}

        <audio ref={remoteAudioRef} autoPlay style={{ display: 'none' }} />
      </VStack>
    </Box>
  );

  async function startPTT() {
    if (!ws) return;
    
    // å¯¾è©±ãƒ¢ãƒ¼ãƒ‰ä¸­ã§ã‹ã¤è‡ªåˆ†ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å ´åˆã®ã¿éŸ³å£°éŒ²éŸ³ã‚’è¨±å¯
    if (dialogueActive && dialogueRequester === myClientId) {
      // å¯¾è©±ãƒ¢ãƒ¼ãƒ‰ä¸­ã¯éŸ³å£°éŒ²éŸ³ã‚’é–‹å§‹
      try {
        const stream = await navigator.mediaDevices.getUserMedia({ 
          audio: {
            sampleRate: 24000,
            channelCount: 1,
            echoCancellation: true,
            noiseSuppression: true
          } 
        });
        
        const mediaRecorder = new MediaRecorder(stream, {
          mimeType: 'audio/webm;codecs=opus',
          audioBitsPerSecond: 64000 // ã‚ˆã‚Šé«˜å“è³ªãªéŸ³å£°éŒ²éŸ³ï¼ˆ32kbps â†’ 64kbpsï¼‰
        });
        
        mediaRecorderRef.current = mediaRecorder;
        audioChunksRef.current = [];
        
        mediaRecorder.ondataavailable = (event) => {
          if (event.data.size > 0) {
            audioChunksRef.current.push(event.data);
          }
        };
        
        // éŒ²éŸ³é–‹å§‹ï¼ˆã‚¿ã‚¤ãƒ ã‚¹ãƒ©ã‚¤ã‚¹ã‚’å‰Šé™¤ã—ã¦é€£ç¶šéŒ²éŸ³ã‚’æœ‰åŠ¹åŒ–ï¼‰
        mediaRecorder.start(); // ã‚¿ã‚¤ãƒ ã‚¹ãƒ©ã‚¤ã‚¹ãªã—ã§é€£ç¶šéŒ²éŸ³
        setIsRecording(true);
        console.log('PTT started for dialogue - recording audio for AI DJ');
      } catch (error) {
        console.error('Failed to start audio recording:', error);
        alert('ãƒã‚¤ã‚¯ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒæ‹’å¦ã•ã‚Œã¾ã—ãŸã€‚ãƒ–ãƒ©ã‚¦ã‚¶ã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚');
      }
    } else {
      // é€šå¸¸ã®PTT
      console.log('PTT started - normal mode');
    }
  }

  async function stopPTT() {
    if (!ws) return;
    
    // å¯¾è©±ãƒ¢ãƒ¼ãƒ‰ä¸­ã§ã‹ã¤è‡ªåˆ†ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®å ´åˆã®ã¿éŸ³å£°éŒ²éŸ³ã‚’åœæ­¢
    if (dialogueActive && dialogueRequester === myClientId && mediaRecorderRef.current && isRecording) {
      // å¯¾è©±ãƒ¢ãƒ¼ãƒ‰ä¸­ã¯éŸ³å£°éŒ²éŸ³ã‚’åœæ­¢ã—ã¦é€ä¿¡
      return new Promise<void>((resolve) => {
        // æ—¢å­˜ã®onstopãƒãƒ³ãƒ‰ãƒ©ãƒ¼ã‚’ã‚¯ãƒªã‚¢ã—ã¦ã‹ã‚‰æ–°ã—ã„ã‚‚ã®ã‚’è¨­å®š
        if (mediaRecorderRef.current) {
          mediaRecorderRef.current.onstop = null;
          
          mediaRecorderRef.current.onstop = async () => {
            try {
              const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm' });
              
              if (audioBlob.size > 0) {
                // WebMéŸ³å£°ã‚’PCM16ã«å¤‰æ›ï¼ˆåŠ¹ç‡çš„ãªå‡¦ç†ï¼‰
                const AudioContextClass = window.AudioContext || (window as typeof window & { webkitAudioContext: typeof AudioContext }).webkitAudioContext;
                const audioContext = new AudioContextClass();
                const arrayBuffer = await audioBlob.arrayBuffer();
                const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                
                // ãƒ¢ãƒãƒ©ãƒ«ã€24kHzã€PCM16ã«å¤‰æ›
                const sampleRate = 24000;
                const length = Math.floor(audioBuffer.length * sampleRate / audioBuffer.sampleRate);
                const pcm16Data = new Int16Array(length);
                
                // åŠ¹ç‡çš„ãªãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ã¨PCM16å¤‰æ›
                const sourceData = audioBuffer.getChannelData(0); // ãƒ¢ãƒãƒ©ãƒ«
                const ratio = audioBuffer.sampleRate / sampleRate;
                for (let i = 0; i < length; i++) {
                  const sourceIndex = Math.floor(i * ratio);
                  const sample = sourceData[sourceIndex] || 0;
                  pcm16Data[i] = Math.round(sample * 32767); // ç°¡ç´ åŒ–ã•ã‚ŒãŸå¤‰æ›
                }
                
                // éŸ³å£°ã®é•·ã•ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆ25ms = 600ã‚µãƒ³ãƒ—ãƒ«ï¼‰
                const durationMs = (pcm16Data.length / sampleRate) * 1000;
                console.log(`Audio duration: ${durationMs.toFixed(2)} ms (${pcm16Data.length} samples)`);
                
                if (durationMs < 25) {
                  console.log('Audio too short (< 25ms), skipping send to avoid buffer errors');
                  setIsRecording(false);
                  resolve();
                  return;
                }
                
                // Base64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ï¼ˆã‚¹ã‚¿ãƒƒã‚¯ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼ã‚’é˜²ããŸã‚å®‰å…¨ãªæ–¹æ³•ã‚’ä½¿ç”¨ï¼‰
                const uint8Array = new Uint8Array(pcm16Data.buffer);
                const base64Audio = btoa(Array.from(uint8Array, byte => String.fromCharCode(byte)).join(''));
                
                const message = {
                  type: 'input_audio_buffer.append',
                  audio: base64Audio
                };
                ws.send(JSON.stringify(message));
                
                // éŸ³å£°ã‚’ã‚³ãƒŸãƒƒãƒˆ
                const commitMessage = {
                  type: 'input_audio_buffer.commit'
                };
                ws.send(JSON.stringify(commitMessage));
                
                console.log(`PTT stopped for dialogue - audio sent to AI DJ (${pcm16Data.length} samples, ${durationMs.toFixed(2)}ms, ${(audioBlob.size / 1024).toFixed(2)}KB, efficient mode)`);
              } else {
                console.log('No audio data recorded');
              }
              
              // ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’åœæ­¢
              if (mediaRecorderRef.current && mediaRecorderRef.current.stream) {
                mediaRecorderRef.current.stream.getTracks().forEach(track => track.stop());
              }
              
              setIsRecording(false);
              resolve();
            } catch (error) {
              console.error('Failed to process audio:', error);
              setIsRecording(false);
              resolve();
            }
          };
          
          mediaRecorderRef.current.stop();
        } else {
          setIsRecording(false);
          resolve();
        }
      });
    } else {
      // é€šå¸¸ã®PTT
      console.log('PTT stopped - normal mode');
    }
  }
}